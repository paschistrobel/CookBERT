{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prepare_for_cross_validation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOolpKssGo8vykw3YSKbX8G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Connect to Google Drive"],"metadata":{"id":"nyIMOqDysO2f"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ubNLHvP8Zok","executionInfo":{"status":"ok","timestamp":1645642147475,"user_tz":-60,"elapsed":173,"user":{"displayName":"Paschi Strobel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjobUJCA_Ck2VfNovLz59RHEuLDra_PAURiUuov=s64","userId":"06759777096404192052"}},"outputId":"7bcde6cb-d6eb-4638-cdb6-00769bd911ee"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/BachelorThesis/datasets/cookversational_search\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/BachelorThesis/datasets/cookversational_search"]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"ZBjaYpIO97L2"}},{"cell_type":"code","source":["import pandas as pd\n","pd.set_option('display.max_columns', None)\n","data = pd.read_csv(\"cookversational_search_dataset.csv\")\n","data.head(10)"],"metadata":{"id":"iZ057fOf8_qS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Data"],"metadata":{"id":"bqYSj8eo-_xa"}},{"cell_type":"markdown","source":["Drop columns that are not needed and rename relevant ones."],"metadata":{"id":"B_5c9lBos1f6"}},{"cell_type":"code","source":["data = data[['id', 'level_1', 'utterance_english', 'tp', 'seq']] # extract relevant columns\n","data = data.rename(columns={'utterance_english': 'utterance_no_context'}) # rename column\n","data.head(10)"],"metadata":{"id":"u5bwesRRswDU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Add Data for Condition \"1 Previous Turn\"\n","The CookversationalSearch dataset only contains one utterance that should be classified. Previous utterances can help to better understand the context and thus the previous utterance is added to each utterance."],"metadata":{"id":"-dCilWcxtHxe"}},{"cell_type":"code","source":["utterances_1_prev_turn = []\n","prev_utterance = \"\"\n","for index, row in data.iterrows():\n","  if row['seq'] == 1: # first utterance of test person --> no context available yet\n","    prev_utterance = \"\"\n","  utt = prev_utterance + \" \" + row['utterance_no_context'] # append the previous utterance before the current utterance\n","  utterances_1_prev_turn.append(utt)\n","  prev_utterance = row['utterance_no_context'] # put current utterance in memory as it will be the predecessor of the next one\n","\n","data['utterance_1_prev_turn'] = utterances_1_prev_turn # append the utterances with context as column to the dataframe\n","data.head(5)\n","\n","data_no_context = data[['id', 'level_1', 'utterance_no_context']] # select the data for the \"no context\" condition\n","data_no_context = data_no_context.rename(columns={'level_1': 'label', 'utterance_no_context': 'text'}) # rename columns\n","\n","data_prev_utterance = data[['id', 'level_1', 'utterance_1_prev_turn']] # select the data for the \"1 previous utterance\" condition\n","data_prev_utterance = data_prev_utterance.rename(columns={'level_1': 'label', 'utterance_1_prev_turn': 'text'}) # rename columns\n","print(\"data with no context: \")\n","print(data_no_context.head(10))\n","print(\"\\ndata with no one previous utterance as context: \")\n","print(data_prev_utterance.head(10))"],"metadata":{"id":"9Qp3qMOB_SCj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save the datasets for the different conditions in csv files:"],"metadata":{"id":"KS0-bYlDvLkc"}},{"cell_type":"code","source":["data_no_context.to_csv(\"cookversational_search_no_context.csv\")\n","data_prev_utterance.to_csv(\"cookversational_search_1_prev_utterance.csv\")"],"metadata":{"id":"mdKyht2saa6P"},"execution_count":null,"outputs":[]}]}