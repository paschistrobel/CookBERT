{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPrt3Hindx4Wjqm849osU84"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Connect to Google Drive and change directory"],"metadata":{"id":"yjdkE9pzF60p"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv8wLVtMFuju"},"outputs":[],"source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/BachelorThesis/"]},{"cell_type":"markdown","source":["# Prepare data for finetuning\n","To successfully run the finetuning script on the custom 'cookversational_search' data, the data must be of a specific format:\n","\n","*   The column that contains the ground truth/ the correct class label is called \"label\"\n","*   The column that contains the text to be classified is called \"sentence\"\n","\n","Therefore the data will be of format:\n","```\n","id  |  label  |  sentence\n","```\n","\n","Additionally, the train- and validation file containing the data should be of csv or json format. \n","\n","Also make sure that the columns in csv file are separated by ','. Other separators like '\\t' or ';' might not be processed correctly.\n","\n","The processing of the data according to these requirements is done in another jupyter notebook (see prepare_for_cross_validation.ipynb)"],"metadata":{"id":"nq3EMwWHSeef"}},{"cell_type":"markdown","source":["# Perform required installations "],"metadata":{"id":"33gOhgkGGG-0"}},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"id":"MqEOagIOGLdr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run finetuning script\n","For Finetuning BERT on Text Classification, the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py) (Retrieved at: 10.01.2022) script from ü§ó[Huggingface Transformer library](https://huggingface.co/transformers/) was used and slightly modified."],"metadata":{"id":"hTjUdVAtGOWt"}},{"cell_type":"code","source":["total_folds = 10 # number of folds for cross validation"],"metadata":{"id":"832D_qbMP81k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For CookBERT use\n","# --model_name_or_path=CookBERT/further_pretraining/model_output/checkpoint-final\n","# --output_dir=CookBERT/finetuning_for_downstream_tasks/text_classification/model_output/CookBERT/  + no_context OR 1_prev_utterance\n","\n","# For FoodBERT use\n","# --model_name_or_path=otherModels/checkpoint-final\n","# --output_dir=CookBERT/finetuning_for_downstream_tasks/text_classification/model_output/FoodBERT/  + no_context OR 1_prev_utterance\n","\n","# For BERT base uncased use\n","# --model_name_or_path=bert-base-uncased\n","# --output_dir=CookBERT/finetuning_for_downstream_tasks/text_classification/model_output/bert-base-uncased/  + no_context OR 1_prev_utterance\n","\n","# Data to use:\n","# --data_path=datasets/cookversational_search/cookversational_search_no_context.csv     for no context\n","# --data_path=datasets/cookversational_search/cookversational_search_1_prev_utterance.csv     for context\n","\n","\n","# todo:\n","# - f√ºr mehrere Epochen trainiern und gucken, ob class weights angepasst werden m√ºssen\n","# - funktion zum laden von foodbert hinzuf√ºgen\n","# - resultate in separaten Ordner abspeichern\n","for fold in range(total_folds):\n","  !python CookBERT/finetuning_for_downstream_tasks/text_classification/run_classification.py \\\n","  --model_name_or_path=otherModels/checkpoint-final \\\n","  --do_train \\\n","  --do_predict \\\n","  --total_folds=$total_folds \\\n","  --fold=$fold \\\n","  --output_dir=CookBERT/finetuning_for_downstream_tasks/text_classification/model_output/FoodBERT/no_context \\\n","  --overwrite_output_dir=True \\\n","  --data_path=datasets/cookversational_search/cookversational_search_no_context.csv \\\n","  --num_train_epochs=4 \\\n","  --save_strategy=no \\\n","  --learning_rate=2e-5 \\\n","  --per_device_train_batch_size=16 \\\n","  --gradient_accumulation_steps=2 \\\n","  --seed=42 \\"],"metadata":{"id":"J8jyPlbxGiZv"},"execution_count":null,"outputs":[]}]}