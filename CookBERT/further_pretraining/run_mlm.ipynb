{"cells":[{"cell_type":"markdown","metadata":{"id":"H2aj0ITJwqj9"},"source":["# Connect to Google Drive and change directory\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20379,"status":"ok","timestamp":1643961295583,"user":{"displayName":"Paschi Strobel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjobUJCA_Ck2VfNovLz59RHEuLDra_PAURiUuov=s64","userId":"06759777096404192052"},"user_tz":-60},"id":"hb_8BgHBlQec","outputId":"5b2d3294-2146-4f64-abc4-3e3ef223af3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/BachelorThesis\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/BachelorThesis/"]},{"cell_type":"markdown","metadata":{"id":"O9TRJUSYwqL1"},"source":["# Installations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWW5GYaH0cx_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643961310105,"user_tz":-60,"elapsed":1535,"user":{"displayName":"Paschi Strobel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjobUJCA_Ck2VfNovLz59RHEuLDra_PAURiUuov=s64","userId":"06759777096404192052"}},"outputId":"f76e8fe3-455c-4857-ceb4-0c9fa639b625"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, huggingface-hub, transformers, datasets\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.3 frozenlist-1.3.0 fsspec-2022.1.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2 xxhash-2.0.2 yarl-1.7.2\n"]}],"source":["!pip install datasets transformers"]},{"cell_type":"markdown","source":["# GPU Support"],"metadata":{"id":"7H5_s-m4Iteh"}},{"cell_type":"markdown","source":["## Enable GPU"],"metadata":{"id":"6X-ps7uTJP_Y"}},{"cell_type":"markdown","source":["To enable GPUs for the notebook:\n","- Navigate to Editâ†’Notebook Settings\n","- select GPU from the Hardware Accelerator drop-down\n","Next, we'll confirm that we can connect to the GPU with tensorflow:"],"metadata":{"id":"3Ediq-N5IyiI"}},{"cell_type":"code","source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"lmpgYW2fIs5c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check which GPU was allocated in the given session:"],"metadata":{"id":"csNTHSn4I-Ts"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"id":"7epzzUdqJCH9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPU Speedup relative to CPU"],"metadata":{"id":"oi69gSbLJU_-"}},{"cell_type":"markdown","source":["This example constructs a typical convolutional neural network layer over a random image and manually places the resulting ops on either the CPU or the GPU to compare execution speed."],"metadata":{"id":"nvZPnAagJZ8o"}},{"cell_type":"code","source":["import timeit\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise SystemError('GPU device not found')\n","\n","def cpu():\n","  with tf.device('/cpu:0'):\n","    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n","    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n","    return tf.math.reduce_sum(net_cpu)\n","\n","def gpu():\n","  with tf.device('/device:GPU:0'):\n","    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n","    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n","    return tf.math.reduce_sum(net_gpu)\n","  \n","# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n","cpu()\n","gpu()\n","\n","# Run the op several times.\n","print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n","      '(batch x height x width x channel). Sum of ten runs.')\n","print('CPU (s):')\n","cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n","print(cpu_time)\n","print('GPU (s):')\n","gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n","print(gpu_time)\n","print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"],"metadata":{"id":"m6exV24YJlOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7V1-PAXVzyFY"},"source":["# Run Further Pretraining"]},{"cell_type":"markdown","source":["For domain-adaptive pre-training (DAPT) of BERT on the RecipeNLG dataset, the [run_mlm.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py) (Retrieved at: 06.01.2022) script from ðŸ¤—[Huggingface Transformer library](https://huggingface.co/transformers/) was used and slightly modified.\n","\n","The following code cell runs the modified script and thus starts the training process\n","\n","The **pretraining was startet from the BERT-base-uncased checkpoint**. After every 1000 training steps, a model checkpoint is saved in the *model_output* folder (all the other output can also be found there). These checkpoints can then be loader to continue the pretraining.\n","\n","**Note:** Pretraining takes quite some time (multiple days). Google Colabs GPU allocation per user is restricted to 12 hours (24 hours for pro users, respectively), thus saving checkpoints and continuing from there is necessary!"],"metadata":{"id":"lZvBIw77L8d6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BpVsTLrmLgw"},"outputs":[],"source":["!python CookBERT/further_pretraining/run_mlm.py \\\n","--model_name_or_path=bert-base-uncased \\\n","--output_dir=CookBERT/further_pretraining/model_output \\\n","--do_train \\\n","--do_eval \\\n","--validation_split_percentage=5 \\\n","--train_file=datasets/recipeNLG/recipeNLG_instructions.txt \\\n","--per_device_train_batch_size=16 \\\n","--per_device_eval_batch_size=16 \\\n","--gradient_accumulation_steps=2 \\\n","--learning_rate=2e-5 \\\n","--num_train_epochs=3 \\\n","--save_total_limit=10 \\\n","--save_strategy=steps \\\n","--save_steps=1000 \\\n","--line_by_line \\\n","--max_seq_length=256 \\\n","--evaluation_strategy=steps \\\n","--eval_steps=1000 \\"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["H2aj0ITJwqj9","O9TRJUSYwqL1","7H5_s-m4Iteh"],"machine_shape":"hm","name":"run_mlm.ipynb","provenance":[],"authorship_tag":"ABX9TyN0+gZ+Ff2JNRmH+e7n6YgY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}